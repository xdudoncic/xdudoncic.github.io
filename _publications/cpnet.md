---
title: "Which Target to Focus on: Class-Perception for Semantic Segmentation of Remote Sensing"
collection: publications
permalink: /publication/2023-05-19-cpnet
excerpt: "<br/><img src='/images/cpnet.png' width='500'>"
date: 2023-05-19
preauthors: Sun, Long and
me: Shao, Yilin,
postauthors: and Li, Lingling and Shao, Yilin and Jiao, Licheng and Liu, Xu and Chen, Puhua and Liu, Fang and Yang, Shuyuan and Hou, Biao
venue: 'IEEE Transactions on Geoscience and Remote Sensing'
---

## Abstract

Deep-learning-based (DL) methods have dominated the task of semantic segmentation of remote sensing images. However, the sizes of different objects vary widely, and there is a great deal of label noise due to the inevitable shadows. Therefore, there is an urgent need for a method that can precisely handle complex ground data. In this article, we propose an interclass enhanced network (ICEN) for representing features of varying sizes. It comprises two branches: sparse representation network (SPN) and feature extraction network (FEN). Then, a class-perception block (CPB) is inserted between the two branches to instruct the SPNâ€™s low-level semantic features to be merged into the deeper network. Such a block can reduce label noise in remote sensing image segmentation. In addition, the proposed EIRI provides a more precise classification process for target edges containing many misclassified points without requiring excessive computational overhead. The experimental results of our proposed class-perception network (C-PNet) achieve competitive performance on the Vaihingen, Potsdam, LoveDA, and UAVid datasets.


PDF available  via [IEEE Xplore](https://ieeexplore.ieee.org/document/10129940) 
